{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define global params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_info = \"Informaci√≥n adicional\"\n",
    "additional_info = \"additionalInfo\"\n",
    "prepared_data_loc = \"/Users/abdalrhman/Documents/preparationphase/prepared_data/\"\n",
    "cleaned_data_loc = \"/Users/abdalrhman/Documents/preparationphase/prepared_data/cleaned/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFiveAdditionalData(df):\n",
    "\n",
    "    # Define the regex pattern\n",
    "    pattern = r'(?P<additionalInfoDate>\\d{2}/\\d{2}/\\d{4}) / (?P<additionalInfo1>[^/]+) (-|/) (?P<additionalInfo2>[^/]+) / (?P<additionalInfo3>[^/]+) / (?P<additionalInfo4>[^/]+) / (?P<additionalInfo5>[^/]+)'\n",
    "\n",
    "    # Iterate through each line and extract information using regex\n",
    "    for index, row in df.iterrows():\n",
    "        if not pd.isna(row[additional_info]):\n",
    "            match = re.match(pattern, row[additional_info])\n",
    "            if match:\n",
    "                df.loc[index, additional_info + \"date\"] = match[additional_info + \"date\"]\n",
    "                df.loc[index, additional_info + \"1\"] = match[additional_info + \"1\"]\n",
    "                df.loc[index, additional_info + \"2\"] = match[additional_info + \"2\"]\n",
    "                df.loc[index, additional_info + \"3\"] = match[additional_info + \"3\"]\n",
    "                df.loc[index, additional_info + \"4\"] = match[additional_info + \"4\"]\n",
    "                df.loc[index, additional_info + \"5\"] = match[additional_info + \"5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFourAdditionalData(df):\n",
    "# Define the regex pattern\n",
    "    pattern = r'(?P<additionalInfoDate>\\d{2}/\\d{2}/\\d{4}) / (?P<additionalInfo1>[^/]+)(-|/) (?P<additionalInfo2>[^/]+) / (?P<additionalInfo3>\\d+) / (?P<additionalInfo4>[^/]+)'\n",
    "\n",
    "# Iterate through each line and extract information using regex\n",
    "    for index, row in df.iterrows():\n",
    "        if not pd.isna(row[additional_info]):\n",
    "            match = re.match(pattern, row[additional_info])\n",
    "            if match:\n",
    "                df.loc[index, additional_info + \"date\"] = match[additional_info + \"date\"]\n",
    "                df.loc[index, additional_info + \"1\"] = match[additional_info + \"1\"]\n",
    "                df.loc[index, additional_info + \"2\"] = match[additional_info + \"2\"]\n",
    "                df.loc[index, additional_info + \"3\"] = match[additional_info + \"3\"]\n",
    "                df.loc[index, additional_info + \"4\"] = match[additional_info + \"4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicates and export files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1 = pd.read_csv(prepared_data_loc + 'P10_Entrada_de_material.csv')\n",
    "df1.drop_duplicates()\n",
    "csv_file_path = cleaned_data_loc + \"P10_Entrada_de_material.csv\"\n",
    "df1.to_csv(csv_file_path, index=False)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(prepared_data_loc + 'P22_Asignacion_de_Rack_Lavadora.csv')\n",
    "df2.drop_duplicates()\n",
    "csv_file_path = cleaned_data_loc + \"P22_Asignacion_de_Rack_Lavadora.csv\"\n",
    "df2.to_csv(csv_file_path, index=False)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(prepared_data_loc + 'P31_Carga_de_Lavadora.csv')\n",
    "df3.drop_duplicates()\n",
    "extractFiveAdditionalData(df3)\n",
    "csv_file_path = cleaned_data_loc + \"P31_Carga_de_Lavadora.csv\"\n",
    "df3.to_csv(csv_file_path, index=False)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_csv(prepared_data_loc + 'P32_Carga_de_Lavadora_Liberada.csv')\n",
    "df4.drop_duplicates()\n",
    "extractFiveAdditionalData(df4)\n",
    "csv_file_path = cleaned_data_loc + \"P32_Carga_de_Lavadora_Liberada.csv\"\n",
    "df4.to_csv(csv_file_path, index=False)\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_csv(prepared_data_loc + 'P41_Inicio_de_Montaje.csv')\n",
    "df5.drop_duplicates()\n",
    "csv_file_path = cleaned_data_loc + \"P41_Inicio_de_Montaje.csv\"\n",
    "df5.to_csv(csv_file_path, index=False)\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.read_csv(prepared_data_loc + 'P42_Produccion_montada.csv')\n",
    "df6.drop_duplicates()\n",
    "csv_file_path = cleaned_data_loc + \"P42_Produccion_montada.csv\"\n",
    "df6.to_csv(csv_file_path, index=False)\n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = pd.read_csv(prepared_data_loc + 'P51_Carga_de_Esterilizador.csv')\n",
    "df7.drop_duplicates()\n",
    "extractFourAdditionalData(df7)\n",
    "csv_file_path = cleaned_data_loc + \"P51_Carga_de_Esterilizador.csv\"\n",
    "df7.to_csv(csv_file_path, index=False)\n",
    "df7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = pd.read_csv(prepared_data_loc + 'P52_Carga_de_esterilizador_liberada.csv')\n",
    "df8.drop_duplicates()\n",
    "csv_file_path = cleaned_data_loc + \"P52_Carga_de_esterilizador_liberada.csv\"\n",
    "df8.to_csv(csv_file_path, index=False)\n",
    "df8.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = pd.read_csv(prepared_data_loc + 'P60_Comisionado.csv')\n",
    "df9.drop_duplicates()\n",
    "csv_file_path = cleaned_data_loc + \"P60_Comisionado.csv\"\n",
    "df9.to_csv(csv_file_path, index=False)\n",
    "df9.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
